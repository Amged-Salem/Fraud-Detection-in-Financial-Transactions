# Financial Fraud Detection with PySpark

## Project Overview
This project focuses on detecting fraudulent transactions in financial services using a synthetic dataset generated by PaySim. The analysis addresses the challenges of big and imbalanced data by leveraging PySpark for scalability and efficiency.

### Background
Financial transaction datasets are often private, making it challenging to access real-world data for fraud detection research. PaySim provides a synthetic dataset that mimics real-world transaction behavior and includes injected fraudulent activities to evaluate detection models.

### Goal
The primary objective is to develop a generalized model for big and imbalanced data suitable for real-world fraud detection applications. PySpark is utilized to handle the big data aspect effectively.

---

## Dataset

The dataset used in this project is publicly available on Kaggle:
[PaySim Synthetic Financial Dataset](https://www.kaggle.com/datasets/ealaxi/paysim1)

### Data Description
The dataset contains 11 features:

- **step**: Unit of time (1 step = 1 hour).
- **type**: Transaction type (e.g., CASH-IN, CASH-OUT, DEBIT, PAYMENT, TRANSFER).
- **amount**: Transaction amount in local currency.
- **nameOrig**: Customer initiating the transaction.
- **oldbalanceOrg**: Initial balance of the sender.
- **newbalanceOrig**: Balance of the sender after the transaction.
- **nameDest**: Customer receiving the transaction.
- **oldbalanceDest**: Initial balance of the recipient (missing for merchants).
- **newbalanceDest**: Balance of the recipient after the transaction (missing for merchants).
- **isFraud**: Label for fraudulent transactions.
- **isFlaggedFraud**: Transactions flagged as fraudulent (e.g., transfers > 200,000).

---

## Methodology

### Tools and Technologies
- **PySpark**: To handle large-scale data efficiently.
- **Machine Learning**: Fraud detection using classification algorithms.
- **Big Data Techniques**: Optimized handling of imbalanced data.

### Steps
1. **Data Loading and Cleaning**:
   - Read the dataset using PySpark.
   - Handle missing values and preprocess features.
2. **Exploratory Data Analysis (EDA)**:
   - Analyze data distribution.
   - Visualize transaction patterns and fraudulent activity.
3. **Model Development**:
   - Train a machine learning model to classify transactions as fraudulent or legitimate.
4. **Evaluation**:
   - Evaluate the model's performance using metrics such as accuracy, precision, recall, and F1-score.

---

## Results

### Testing Performance
- **Accuracy**: 99.85%
- **Precision**: 92% (Fraud class)
- **Recall**: 54% (Fraud class)
- **F1-Score**: 68% (Fraud class)

### Training Performance
- **Accuracy**: 99.84%
- **Precision**: 91% (Fraud class)
- **Recall**: 53% (Fraud class)
- **F1-Score**: 67% (Fraud class)

---

## Usage

### Requirements
- Python environment with PySpark installed.
- Dataset downloaded from Kaggle.

### Steps to Run
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/financial-fraud-detection.git
   ```
2. Navigate to the project directory:
   ```bash
   cd financial-fraud-detection
   ```
3. Run the notebook:
   ```bash
   jupyter notebook pyspark_RF_fraud_detection.ipynb
   ```

---

## References

- [PaySim Synthetic Financial Dataset](https://www.kaggle.com/datasets/ealaxi/paysim1)
- Arjun Joshua's [Predicting Fraud in Financial Payment Services](https://www.kaggle.com/arjunjoshua/predicting-fraud-in-financial-payment-services)

---

## Acknowledgments
This project structure and initial inspiration were borrowed from existing works in fraud detection and adapted to leverage PySpark for big data handling.
